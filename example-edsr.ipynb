{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Modified By Sohaib Anwaar\n",
    "\n",
    "This code is modified for tensorflow 2.\n",
    "\n",
    "Hardware and software Compatibility:\n",
    "\n",
    "    3070 RTX nvidia\n",
    "    Intel 10400F processor (CPU)\n",
    "    Ubuntu 18.04\n",
    "    tensorflow 2.0\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "for gpu_instance in physical_devices: \n",
    "    tf.config.experimental.set_memory_growth(gpu_instance, True)\n",
    "\n",
    "from tensorflow.compat.v1.keras.backend import set_session\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "set_session(sess)\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data import DIV2K\n",
    "from model.edsr import edsr\n",
    "from train import EdsrTrainer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of residual blocks\n",
    "depth = 16\n",
    "\n",
    "# Super-resolution factor\n",
    "scale = 4\n",
    "\n",
    "# Downgrade operator\n",
    "downgrade = 'bicubic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of model weights (needed for demo)\n",
    "weights_dir = f'weights/edsr-{depth}-x{scale}'\n",
    "weights_file = os.path.join(weights_dir, 'weights.h5')\n",
    "\n",
    "os.makedirs(weights_dir, exist_ok=True)\n",
    "\n",
    "dataset_path = \"\"\n",
    "\n",
    "images_dir='/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images'\n",
    "caches_dir='/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/caches'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "You don't need to download the DIV2K dataset as the required parts are automatically downloaded by the `DIV2K` class. By default, DIV2K images are stored in folder `.div2k` in the project's root directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "div2k_train = DIV2K(images_dir= images_dir, caches_dir=caches_dir, scale=scale, subset='train', downgrade=downgrade)\n",
    "div2k_valid = DIV2K(images_dir= images_dir, caches_dir=caches_dir,scale=scale, subset='valid', downgrade=downgrade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/15_HGE_Segx4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/36x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/5x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/8x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/Y28x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/26_HGE_Segx4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/19x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/no_9x4.png', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/20x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/Y103x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/1x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/Y91x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/No11x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/17_HGE_Segx4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/Y24x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/25_HGE_Segx4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/9_HGE_Segx4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/32x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/18_HGE_Segx4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/12_HGE_Segx4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/16x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/N21x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/Y52x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/Y108x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/22_HGE_Segx4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/14_HGE_Segx4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/no_10x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/24x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/33x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/no_7x4.jpeg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/12x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/34x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/31x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/No19x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/Y6x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/Y41x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/22x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/23_HGE_Segx4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/24_HGE_Segx4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/Y257x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/18x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/no_94x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/29_HGE_Segx4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/N11x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/6x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/2_nox4.jpeg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/19_HGE_Segx4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/23x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/27_HGE_Segx4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/3x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/13_HGE_Segx4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/Y27x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/31_HGE_Segx4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/21x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/Y29x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/48_nox4.jpeg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/1_nox4.jpeg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/7x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/4x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/2x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/11x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/30x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/Y104x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/Y26x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/16_HGE_Segx4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/15x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/Y51x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/11_HGE_Segx4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/26x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/10_HGE_Segx4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/Y96x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/27x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/9x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/14x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/Y55x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/10x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/6_HGE_Segx4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/17x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/Y46x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/40x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/13x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/29x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/Y74x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/8_HGE_Segx4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/39x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/37x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_train_LR_bicubic/X4/Y9x4.jpg']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_valid_LR_bicubic/X4/25x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_valid_LR_bicubic/X4/4x4x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_valid_LR_bicubic/X4/28_HGE_Segx4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_valid_LR_bicubic/X4/21_HGE_Segx4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_valid_LR_bicubic/X4/30_HGE_Segx4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_valid_LR_bicubic/X4/6_HGE_Segx4x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_valid_LR_bicubic/X4/10_HGE_Segx4x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_valid_LR_bicubic/X4/Y188x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_valid_LR_bicubic/X4/35x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_valid_LR_bicubic/X4/7_HGE_Segx4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_valid_LR_bicubic/X4/Y162x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_valid_LR_bicubic/X4/28x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_valid_LR_bicubic/X4/38x4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_valid_LR_bicubic/X4/32_HGE_Segx4.jpg', '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_valid_LR_bicubic/X4/20_HGE_Segx4.jpg']\n"
     ]
    }
   ],
   "source": [
    "train_ds = div2k_train.dataset(batch_size=16, random_transform=True)\n",
    "valid_ds = div2k_valid.dataset(batch_size=1, random_transform=False, repeat_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "### Pre-trained models\n",
    "\n",
    "If you want to skip training and directly run the demo below, download [weights-edsr-16-x4.tar.gz](https://martin-krasser.de/sisr/weights-edsr-16-x4.tar.gz) and extract the archive in the project's root directory. This will create a `weights/edsr-16-x4` directory containing the weights of the pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = EdsrTrainer(model=edsr(scale=2, num_res_blocks=depth), \n",
    "                      checkpoint_dir=f'.ckpt/edsr-{depth}-xy{scale}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /media/sohaib/additional_/DataScience/super_resolution/super-resolution/train.py:81 train_step  *\n        loss_value = self.loss(hr, sr)\n    /home/sohaib/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:152 __call__  **\n        losses = call_fn(y_true, y_pred)\n    /home/sohaib/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:256 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /home/sohaib/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /home/sohaib/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:1231 mean_absolute_error\n        return K.mean(math_ops.abs(y_pred - y_true), axis=-1)\n    /home/sohaib/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:1180 binary_op_wrapper\n        raise e\n    /home/sohaib/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:1164 binary_op_wrapper\n        return func(x, y, name=name)\n    /home/sohaib/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /home/sohaib/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:561 subtract\n        return gen_math_ops.sub(x, y, name)\n    /home/sohaib/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/ops/gen_math_ops.py:10317 sub\n        \"Sub\", x=x, y=y, name=name)\n    /home/sohaib/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:750 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    /home/sohaib/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py:592 _create_op_internal\n        compute_device)\n    /home/sohaib/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:3536 _create_op_internal\n        op_def=op_def)\n    /home/sohaib/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:2016 __init__\n        control_input_ops, op_def)\n    /home/sohaib/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1856 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 1200 and 600 for '{{node mean_absolute_error/sub}} = Sub[T=DT_FLOAT](edsr/lambda_2/add, Cast_1)' with input shapes: [16,1200,1200,3], [16,600,600,3].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d8cd386728f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m               \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m               \u001b[0mevaluate_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m               save_best_only=True)\n\u001b[0m",
      "\u001b[0;32m/media/sohaib/additional_/DataScience/super_resolution/super-resolution/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataset, valid_dataset, steps, evaluate_every, save_best_only)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_every\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/sohaib/additional_/DataScience/super_resolution/super-resolution/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataset, valid_dataset, steps, evaluate_every, save_best_only)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mckpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0mloss_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mbound_method_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3885\u001b[0m     \u001b[0;31m# However, the replacer is still responsible for attaching self properly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3886\u001b[0m     \u001b[0;31m# TODO(mdan): Is it possible to do it here instead?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3887\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3888\u001b[0m   \u001b[0mweak_bound_method_wrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_method_wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /media/sohaib/additional_/DataScience/super_resolution/super-resolution/train.py:81 train_step  *\n        loss_value = self.loss(hr, sr)\n    /home/sohaib/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:152 __call__  **\n        losses = call_fn(y_true, y_pred)\n    /home/sohaib/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:256 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /home/sohaib/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /home/sohaib/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:1231 mean_absolute_error\n        return K.mean(math_ops.abs(y_pred - y_true), axis=-1)\n    /home/sohaib/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:1180 binary_op_wrapper\n        raise e\n    /home/sohaib/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:1164 binary_op_wrapper\n        return func(x, y, name=name)\n    /home/sohaib/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /home/sohaib/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:561 subtract\n        return gen_math_ops.sub(x, y, name)\n    /home/sohaib/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/ops/gen_math_ops.py:10317 sub\n        \"Sub\", x=x, y=y, name=name)\n    /home/sohaib/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:750 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    /home/sohaib/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py:592 _create_op_internal\n        compute_device)\n    /home/sohaib/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:3536 _create_op_internal\n        op_def=op_def)\n    /home/sohaib/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:2016 __init__\n        control_input_ops, op_def)\n    /home/sohaib/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1856 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 1200 and 600 for '{{node mean_absolute_error/sub}} = Sub[T=DT_FLOAT](edsr/lambda_2/add, Cast_1)' with input shapes: [16,1200,1200,3], [16,600,600,3].\n"
     ]
    }
   ],
   "source": [
    "# Train EDSR model for 300,000 steps and evaluate model\n",
    "# every 1000 steps on the first 10 images of the DIV2K\n",
    "# validation set. Save a checkpoint only if evaluation\n",
    "# PSNR has improved.\n",
    "trainer.train(train_ds,\n",
    "              valid_ds.take(10),\n",
    "              steps=300000, \n",
    "              evaluate_every=1000, \n",
    "              save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore from checkpoint with highest PSNR\n",
    "trainer.restore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model on full validation set\n",
    "psnrv = trainer.evaluate(valid_ds)\n",
    "print(f'PSNR = {psnrv.numpy():3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weights to separate location (needed for demo)\n",
    "trainer.model.save_weights(weights_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = edsr(scale=scale, num_res_blocks=depth)\n",
    "model.load_weights(weights_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import resolve_single\n",
    "from utils import load_image, plot_sample\n",
    "\n",
    "def resolve_and_plot(lr_image_path):\n",
    "    lr = load_image(lr_image_path)\n",
    "    sr = resolve_single(model, lr)\n",
    "    plot_sample(lr, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolve_and_plot('demo/0869x4-crop.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolve_and_plot('demo/0829x4-crop.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolve_and_plot('demo/0851x4-crop.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.data.experimental import AUTOTUNE\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "#  Transformations\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "\n",
    "def random_crop(lr_img, hr_img, hr_crop_size=96, scale=2):\n",
    "    lr_crop_size = hr_crop_size // scale\n",
    "    lr_img_shape = tf.shape(lr_img)[:2]\n",
    "\n",
    "    lr_w = tf.random.uniform(shape=(), maxval=lr_img_shape[1] - lr_crop_size + 1, dtype=tf.int32)\n",
    "    lr_h = tf.random.uniform(shape=(), maxval=lr_img_shape[0] - lr_crop_size + 1, dtype=tf.int32)\n",
    "\n",
    "    hr_w = lr_w * scale\n",
    "    hr_h = lr_h * scale\n",
    "\n",
    "    lr_img_cropped = lr_img[lr_h:lr_h + lr_crop_size, lr_w:lr_w + lr_crop_size]\n",
    "    hr_img_cropped = hr_img[hr_h:hr_h + hr_crop_size, hr_w:hr_w + hr_crop_size]\n",
    "\n",
    "    return lr_img_cropped, hr_img_cropped\n",
    "\n",
    "\n",
    "def random_flip(lr_img, hr_img):\n",
    "    rn = tf.random.uniform(shape=(), maxval=1)\n",
    "    return tf.cond(rn < 0.5,\n",
    "                   lambda: (lr_img, hr_img),\n",
    "                   lambda: (tf.image.flip_left_right(lr_img),\n",
    "                            tf.image.flip_left_right(hr_img)))\n",
    "\n",
    "\n",
    "def random_rotate(lr_img, hr_img):\n",
    "    rn = tf.random.uniform(shape=(), maxval=4, dtype=tf.int32)\n",
    "    return tf.image.rot90(lr_img, rn), tf.image.rot90(hr_img, rn)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "#  IO\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "\n",
    "def download_archive(file, target_dir, extract=True):\n",
    "    source_url = f'http://data.vision.ee.ethz.ch/cvl/DIV2K/{file}'\n",
    "    target_dir = os.path.abspath(target_dir)\n",
    "    tf.keras.utils.get_file(file, source_url, cache_subdir=target_dir, extract=extract)\n",
    "    os.remove(os.path.join(target_dir, file))\n",
    "\n",
    "\n",
    "def dataset(batch_size=16, repeat_count=None, random_transform=True):\n",
    "    \n",
    "    hr = div2k_train.hr_dataset()\n",
    "    lr = div2k_train.lr_dataset()\n",
    "    ds = tf.data.Dataset.zip((lr, hr))\n",
    "#     if random_transform:\n",
    "#         ds = ds.map(lambda lr, hr: random_crop(lr, hr, scale=4), num_parallel_calls=AUTOTUNE)\n",
    "#         ds = ds.map(random_rotate, num_parallel_calls=AUTOTUNE)\n",
    "#         ds = ds.map(random_flip, num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.repeat(repeat_count)\n",
    "#         ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "df = dataset(batch_size=16, repeat_count=None, random_transform=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lr, hr in df.take(1):\n",
    "    print(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr = div2k_train.hr_dataset()\n",
    "lr = div2k_train.lr_dataset()\n",
    "\n",
    "\n",
    "for i in hr.take(1):\n",
    "    print(i.numpy().shape)\n",
    "    \n",
    "\n",
    "for i in lr.take(1):\n",
    "    print(i.numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_valid_LR_bicubic/X4/20_HGE_Segx4.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-db6f4332d819>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_valid_LR_bicubic/X4/20_HGE_Segx4.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   2910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2911\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2912\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2913\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_valid_LR_bicubic/X4/20_HGE_Segx4.jpg'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "Image.open('/media/sohaib/additional_/DataScience/super_resolution/dataset/dataset3/images/DIV2K_valid_LR_bicubic/X4/20_HGE_Segx4.jpg').size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
